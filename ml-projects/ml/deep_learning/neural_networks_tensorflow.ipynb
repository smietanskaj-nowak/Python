# Project
Celem projektu jest wizualizacja działania i porównanie skuteczności dwóch klasyfikatorów działających na zbiorze danych `iris` https://archive.ics.uci.edu/dataset/53/iris

Zbiór `iris` jest też jednym ze zbiorów testowych w bibliotece `sklearn` - załadowano go poleceniem `load_iris` z modułu `sklearn.datasets`. Ładuję go od razu z podziałem na zbiór treningowy/testowy poleceniem
```python
data = tf.tensorflow_datasets.load("iris",split='train[:80%]', as_supervised=True)
```
Można go też zaimportować bezpośrednio ze strony UCI:
```python
!pip install ucimlrepo

from ucimlrepo import fetch_ucirepo 
  
# fetch dataset 
iris = fetch_ucirepo(id=53) 
  
# data (as pandas dataframes) 
X = iris.data.features 
y = iris.data.targets 
  
# metadata 
print(iris.metadata) 
  
# variable information 
print(iris.variables)
```

### Klasyfikator 1 - drzewo decyzyjne

1. Przygotowanie danych treningowych.
2. Wyuczenie modelu.
3. Wizualizacja otrzymanego drzewa decyzyjnego.
4. Wizualizacja tablicy pomyłek (*confusion matrix*).

### Klasyfikator 2 - sieci neuronowe

1. Przygotowanie danych treningowych.
2. Budowa sieci według wybranej architektury.
3. Wyuczenie modelu.
4. Wizualizacja procesu uczenia się (`categorical_loss`, `categorical_accuracy`).
5. Wizualizacja tablicy pomyłek (*confusion matrix*).

### Porównanie skuteczności

Stworzenie infografiki porównującej skuteczność obydwu modeli.


# Klasyfikator 1 - drzewo decyzyjne
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

import tensorflow_datasets as tfds
from sklearn.datasets import load_iris
from sklearn import tree
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split

#!pip install --upgrade scikit-learn
 
# przygotowanie danych treningowych
iris = load_iris()

X, y = load_iris(return_X_y=True) 

print('Class labels:', np.unique(y))
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)

print('y_train:', np.bincount(y_train))
print('y_test:', np.bincount(y_test))

# wybór modelu drzewa decyzyjnego i uczenie
clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=42)

clf = clf.fit(X_train, y_train)

#wizualizacja drzewa decyzyjnego
plt.figure(figsize=(30,30))
tree.plot_tree(clf, filled=True, feature_names=iris.feature_names,
               class_names=list(iris.target_names), fontsize=11, rounded=True)
plt.show()

#ze względu na starszą wersję pakietu scikit-learn, która nie obsługuje metody ConfusionMatrixDisplay.from_estimator
#użyłam klasycznej metody omawianej na 1. laboratorium
y_pred = clf.predict(X_test)
cm = confusion_matrix(y_test, y_pred)

disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=iris.target_names)
disp.plot()
plt.show()

# Klasyfikator 2 - sieć neuronowa
from tensorflow.keras.models import Sequential                 
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, AveragePooling2D
from tensorflow.python.keras.utils import np_utils

#przygotowanie danych - 150 próbek należących do 3 klas
iris = load_iris()
X, y = iris.data, iris.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)

nb_classes = 3 #liczba klas

Y_train = np_utils.to_categorical(y_train,nb_classes)
Y_test = np_utils.to_categorical(y_test,nb_classes)

print(Y_train[0])

#budowa modelu MLP z trzema warstwami z 8 i 6 neuronami w warstwach, 4 cechy wejściowe, na wyjściu 3 klasy (setosa, versicolor, virginica)
model = Sequential()
model.add(Flatten(input_shape=(4,)))                            
model.add(Dense(units=8, activation='relu'))  
model.add(Dense(units=6, activation='relu'))                      
model.add(Dropout(0.2))                                            
model.add(Dense(units=3, activation='softmax'))   

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])
model.summary()

#uczenie modelu, 100 epok
history = model.fit(X_train, Y_train,
          batch_size=8, epochs=100,
          verbose=1,
          validation_data=(X_test, Y_test))

#wizualizacja procesu uczenia się w kolejnych epokach, monitorowanie straty i dokładności klasyfikacji na zbiorze testowym
loss=history.history['loss']
acc=history.history['categorical_accuracy']
val_loss=history.history['val_loss']
val_acc=history.history['val_categorical_accuracy']

plt.figure().suptitle('MLP training process')
plt.subplot(1,2,1)
plt.plot(range(1,len(loss)+1),loss,color='b')
plt.plot(range(1,len(val_loss)+1),val_loss,color='r')
plt.title('Loss')
plt.tight_layout()
plt.legend(['Training loss','Validation loss'])
plt.subplot(1,2,2)
plt.plot(range(1,len(acc)+1),acc,color='b')
plt.plot(range(1,len(val_acc)+1),val_acc,color='orange')
plt.title('Accuracy')
plt.tight_layout()
plt.legend(['Training accuracy','Validation accuracy'])

# ewaluacja modelu, całkiem przyzwoite wartości przy tym prostym modelu i niewielkim zbiorze danych
metrics = model.evaluate(X_test, Y_test,verbose=0)
MLP_loss = metrics[0]
MLP_acc = metrics[1]
print('MLP model of Iris dataset - loss:', MLP_loss)
print('MLP model of Iris dataset - accuracy:', MLP_acc)
#macierz pomyłek dla modelu sieci neuronowej
y_pred_start = model.predict(X_test)
y_pred = np.argmax(y_pred_start, axis=1)
y_true = np.argmax(Y_test, axis=1)
cm = confusion_matrix(y_true, y_pred)

disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=iris.target_names)
disp.plot()
plt.show()
# Porównanie modeli
from sklearn.metrics import log_loss, accuracy_score

y_pred = clf.predict(X_test)
y_probability = clf.predict_proba(X_test)
tree_loss = log_loss(y_test, y_probability)
tree_acc = accuracy_score(y_test, y_pred)
print("Decision tree loss:", tree_loss)
print("Accuracy:", tree_acc)

models = ['Decision Tree', 'MLP']
accuracy = [tree_acc, MLP_acc]
loss = [tree_loss, MLP_loss]

plt.subplot(1,2,1)
plt.bar(models, accuracy, color=['red', 'green'])
plt.ylim(0, 1.1)
plt.grid(True)
plt.title('Accuracy of models')

plt.subplot(1,2,2)
plt.bar(models, loss, color=['red', 'green'])
plt.ylim(0, max(loss) + 0.5)
plt.grid(True)
plt.title('Losses of models')

#accuracy = "★★★☆☆" if MLP_acc > 0.92 else "★★☆☆☆"
#plt.text(0.75, 0.01, f"Accuracy: {accuracy}", fontsize=9, ha='right')

plt.tight_layout()
plt.show()
# Drzewa decyzyjne i ich wizualizacja w `sklearn`



Użyty w przykładzie zbiór danych `wine` stanowi wynik analizy chemicznej win wyprodukowanych w tym samym regionie Włoch, ale z trzech różnych odmian winogron. Oryginalny zbiór danych pochodzi z roku 1988 i był jednym ze zbiorów testowych pakietu do eksploracji danych PARVUS. Niestety w mrokach dziejów zaginęła informacja, o jakie konkretnie odmiany winogron chodzi, dlatego we wszystkich dostępnych wersjach datasetu są one enigmatycznie nazywane odmianami 0,1,2.

Celem modelu jest zaklasyfikowanie win do odmiany 0,1 albo 2.
### Import bibliotek i funkcji
from sklearn.datasets import load_wine
from sklearn import tree
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split

import numpy as np
import matplotlib.pyplot as plt
### Import zbioru danych `wine` z bibliotek testowych `sklearn`
# import 
wine = load_wine()

# import cech (features) X i etykiet (targets) y
X, y = load_wine(return_X_y=True)

# podgląd etykiet
print('Class labels:', np.unique(y))
### Podział na dane treningowe i testowe 80/20
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)

# podgląd liczebności zbiorów
print('y_train:', np.bincount(y_train))
print('y_test:', np.bincount(y_test))
### Budowa drzewa (uczenie modelu)
# wybór modelu - drzewo decyzyjne z domyślnymi ustawieniami
clf = tree.DecisionTreeClassifier()

# uczenie
clf = clf.fit(X_train, y_train)
### Wizualizacja drzewa

Szybką techniką wizualizacji otrzymanego drzewa decyzyjnego jest funkcja `plot_tree` z biblioteki `sklearn` https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html

Własności otrzymanej grafiki:
- pierwsza linijka w opisie każdego węzła zawiera warunek, który jest sprawdzany w danym węźle
- prawda -> gałąź w lewo, fałsz -> gałąź w prawo
- kolor węzła oznacza dominującą liczebnościowo klasę na danym etapie drzewa, opisaną również w ostatniej linijce opisu węzła

Otrzymane drzewo jest dość rozbudowane, dlatego polecam otwarcie go w nowym oknie.

Estetyka grafiki pozostawia wiele do życzenia, dlatego na potrzeby prezentacji popularnonaukowej polecam przerysowanie otrzymanego drzewa w programie graficznym.
plt.figure(figsize=(30,30))
tree.plot_tree(clf, filled=True, feature_names=wine.feature_names,
               class_names=list(wine.target_names), fontsize=11, rounded=True)
plt.show()
### Tablica pomyłek

Tablica pomyłek to czytelna wizualizacja błedów klasyfikacji. Na głównej przekątnej mamy zawsze liczbę poprawnych klasyfikacji dla każdej etykiety, natomiast poza przekątną liczbę błednych klasyfikacji dla każdej pary *(etykieta faktyczna, etykieta przypisana)*.

W przypadku klasyfikatora binarnego otrzymalibyśmy tradycyjną tablicę pomyłek https://pl.wikipedia.org/wiki/Tablica_pomy%C5%82ek wywodzącą się z medycyny.
ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test)
