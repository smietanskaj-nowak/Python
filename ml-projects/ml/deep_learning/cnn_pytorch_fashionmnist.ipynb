# Sieci konwolucyjne w PyTorch
!pip install tqdm
import torch
import torchvision
import math
import numpy as np
from matplotlib import pyplot as plt

from tqdm import tqdm

%matplotlib inline
%config InlineBackend.figure_format = 'retina'
plt.rcParams["figure.figsize"] = [16, 9]
Akcelerator obliczeń.
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(f'Układ obliczeniowy: {device}')
## Zbiór danych

Przygotowuję transformację wejściowych zdjęć. Obecnie jest to sekwencja dwóch operacji:
* zdekodowanie obrazu (`ToImage()`),
* konwersja do tensora PyTorch (`ToDtype()`)
from torchvision.transforms import v2

# Sekwencja operacji wykonujących pre-processing danych wejściowych.
input2tensor = v2.Compose([
    v2.ToImage(),
    v2.ToDtype(torch.float32, scale=True)
])

#train_input2tensor = v2.Compose([
 #   v2.ToImage(),
  #  v2.ToDtype(torch.float32, scale=True),
   # v2.RandomHorizontalFlip(p = 0.5)
#])
Ładowanie danych i wyświetlanie kilku przykładowych obrazów.
train_data = torchvision.datasets.FashionMNIST('/tmp/fmnist', transform=input2tensor,
                                               train=True, download=True)
test_data = torchvision.datasets.FashionMNIST('/tmp/fmnist', transform=input2tensor,
                                              train=False, download=True)
subset = np.random.choice(np.arange(60000), size=16)
plt.figure(figsize=(10,10))
for i in range(16):
    plt.subplot(4,4,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    img, label = train_data[subset[i]]
    plt.imshow(img.squeeze(), cmap=plt.cm.binary)

plt.show()
from torch.utils.data import DataLoader

train_dataloader = DataLoader(train_data, batch_size=256, num_workers=4, shuffle=True)
test_dataloader = DataLoader(test_data, batch_size=256, num_workers=4, shuffle=True)
Funkcje do trenowania i ewaluacji sieci.
def train_network(model, loss_f, opt, train_dataloader, epoch_num):
    # Tryb uczenia sieci
    model.train()

    # Pętla po epokach
    for epoch in range(epoch_num):
        epoch_loss, batch_count = 0, 0

        # Pętla po mini-batchach z modułu ładującego dane
        for images, labels in tqdm(train_dataloader):
            # Zerowanie pochodnych w algorytmie optymalizacji.
            # Poprzednio operację tą trzeba było wykonać ręcznie.
            opt.zero_grad()

            # Wysłanie przykładu uczącego na kartę graficzną
            images = images.to(device)
            labels = labels.to(device)

            # Operacja feed-forward - wynikiem są logity
            logits = model(images)

            # Obliczenie kosztu i wykonanie wstecznej propagacji błędów
            loss = loss_f(logits, labels)
            loss.backward()

            # Aktualizacja wartości parametrów. 
            opt.step()

            epoch_loss += loss.item()
            batch_count += 1

        print(f'Epoka {epoch+1} koszt na zbiorze uczącym: {epoch_loss / batch_count}')
def evaluate_network(model, loss_f, test_dataloader):
    test_loss, batch_count = 0, 0
    correct_predictions  = 0
    example_count = 0

    # Tryb ewaluacji przed predykcją.
    model.eval()

    # Pętla po przykładach testowych
    for images, labels in tqdm(test_dataloader):

        # Wysłanie przykładu na kartę graficzną
        images = images.to(device)
        labels = labels.to(device)

        # Operacja feed-forward
        logits = model(images)

        # Jako przewidywaną klasę przyjmuję klasę z największym logitem
        _, predicted_class = torch.max(logits, 1)

        # Zliczam prawidłowe predykcje
        correct_predictions += (predicted_class == labels).sum().item()
        example_count += len(predicted_class)

        # Obliczam wartość kosztu na zbiorze testowym
        loss = loss_f(logits, labels)
        test_loss += loss.item()
        batch_count += 1

    print(f'Dokładność na zbiorze testowym: {correct_predictions / example_count*100:.2f}%')
    print(f'Koszt na zbiorze testowym: {test_loss / batch_count:.2f}')
## Druga implementacja

Implementacja sieci konwolucyjnej do klasyfikacji obrazów ze zbioru `FashionMNIST`. Wyniki zapisuję w zmiennej `cnn_model`.

W pakiecie PyTorch warstwę konwolucyjną zaimplementowano przez metodę `torch.nn.Conv2d`. Sieć powinna składa się z:
* Dwóch warstw konwolucyjnych, z których pierwsza ma 4 kanały wyjściowe a druga 32 kanały wyjściowe. Obie warstwy powinny mieć kernele o rozmiarze $(3, 3)$ przesuwane w obu osiach co dwa piksele. Warstwy nie powinny mieć paddingu.
* Warstwy w pełni połączonej wyliczającej logity.

Ponadto:
* Po każdej warstwie konwolucyjnej dodano warstwę implementującą aktywację `ReLU` oraz warstwę implementującą operację normalizacji aktywacji (`torch.nn.BatchNorm2d`).
* Przed warstwą w pełni połączoną dodano warstwę rzutującą wolumen konwolucyjny na wektor liczb.

Uwzględniono, że wejściowe obrazy mają jeden kanał (odcienie szarości).
# Implementacja sieci konwolucyjnej
cnn_model = torch.nn.Sequential(
    torch.nn.Conv2d(in_channels=1,
                    out_channels=4,
                    kernel_size=(3,3),
                    stride=(2,2),
                    padding=0),
    torch.nn.ReLU(),
    torch.nn.BatchNorm2d(4),
    torch.nn.Conv2d(in_channels=4,
                    out_channels=32,
                    kernel_size=(3,3),
                    stride=(2,2),
                    padding=0),
    torch.nn.ReLU(),
    torch.nn.BatchNorm2d(32),
    torch.nn.Flatten(),
    torch.nn.Linear(32*6*6, 10)
)
Wysłanie sieci na GPU.
cnn_model.to(device)
Funkcja kosztu i algorytm optymalizacji.
loss_f = torch.nn.CrossEntropyLoss(reduction='mean')
opt = torch.optim.SGD(cnn_model.parameters(), lr=0.01, momentum=0.9)
Trening sieci.
train_network(cnn_model, loss_f, opt, train_dataloader, 20)
Ocena jej skuteczności.
evaluate_network(cnn_model, loss_f, test_dataloader)
